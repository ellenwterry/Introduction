set.seed(102)
quoteData  = read_csv('C:/Users/ellen/Documents/UH/Fall 2020/Data/CRMData.csv')
quoteData$Office = factor(quoteData$Office)
summary(quoteData)
quoteData$Product_ID = factor(quoteData$Product_ID)
quoteData$Competitor_ID = factor(quoteData$Competitor_ID)
quoteData$Office = factor(quoteData$Office)
quoteData$Date_Due = ymd(quoteData$Date_Due)
quoteData$Date_Submitted = ymd(quoteData$Date_Submitted)
quoteData$Date_Required = ymd(quoteData$Date_Required)
quoteData$ATP = ymd(quoteData$ATP)
quoteData$QuoteDiff = as.numeric(quoteData$Competitor_Quote - quoteData$Quote)
quoteData$ATPDiff = as.numeric(quoteData$Date_Required - quoteData$ATP)
quoteData$RFPDiff = as.numeric(quoteData$Date_Due - quoteData$Date_Submitted)
quoteData$Order = factor(quoteData$Order)
quoteData$Product_ID = factor(quoteData$Product_ID)
# always needs to be releveled after csv
quoteData$RSFDesc = factor(quoteData$RSFDesc,
levels = c("Green", "Silver", "Gold", "Platinum"))
quoteData$RSF = factor(quoteData$RSF,
levels = c(1, 2, 3, 4))
quoteData <- quoteData %>% rownames_to_column("SampleID")
newtrain  = quoteData %>% drop_na()
Missing = quoteData %>% anti_join(newtrain, by = "SampleID")
#quoteData$SampleID  <- as.numeric(quoteData$SampleID)
quoteData$QuoteDiff <- quoteData$QuoteDiff/1000
#train <- sample_n(newtrain, nrow(quoteData)-100)
test <- quoteData %>% anti_join(newtrain, by = "SampleID")
xTrain <- select(newtrain, Product_ID, QuoteDiff)
xTest <-  select(test, Product_ID, QuoteDiff)
x_train <- as.numeric(train$QuoteDiff)
y_train <- as.integer(newtrain$Order)
N_train <- length(newtrain)
# Quick Priors:
glm.priors <- glm(Order ~ Product_ID -1, data = newtrain, family = binomial)
mQuotes = model.matrix(Order ~ Product_ID, data = newtrain)
mTrain = model.matrix(Order ~ Product_ID, data = newtrain)
mTest = model.matrix(Order ~ Product_ID, data = test)
beta = as.numeric(glm.priors$coefficients)
# new adjustments
quoteDiff <- as.numeric(train$QuoteDiff)
N_train <- length(quoteDiff)
quoteData$Product_ID = as.numeric(quoteData$Product_ID)
test$Product_ID = as.numeric(test$Product_ID)
newtrain  = quoteData %>% drop_na()
Missing = quoteData %>% anti_join(newtrain, by = "SampleID")
xNewTrain <- select(newtrain, Order, Product_ID, QuoteDiff)
mTrain = model.matrix(Order ~ Product_ID + QuoteDiff, data = xNewTrain)[,-1]
mTest = model.matrix(Order ~ Product_ID + QuoteDiff, data = test)[,-1]
#xNewTrain$Order = xNewTrain$Order + 1
# back and forth here:
xNewTrain$Order = as.numeric(xNewTrain$Order) -1
stanMod <- '
data {
int N_train;
int K;
int y_train[N_train];
matrix[N_train, K] x_train;
real p_b[K];
real<lower = 0> p_sb[K];
}
parameters {
vector[K] beta;
}
transformed parameters {
vector[N_train] y_hat;
for(n in 1:N_train)
y_hat[n] = x_train[n]*beta;
}
model {
target += normal_lpdf(beta | p_b, p_sb);
target += bernoulli_lpmf(y_train | inv_logit(y_hat));
}
'
beta = as.numeric(glm.priors$coefficients)
betaSigma  = rep(.2, 6)
fit <- stan(model_code=stanMod,
data = list(
N_train=nrow(mTrain),
K=ncol(mTrain),
y_train=as.numeric(newtrain$Order),
x_train=mTrain,
p_b = beta,
p_sb = betaSigma
))
betaSigma
View(newtrain)
library(lme4)
library(tidyverse)
library(rstan)
library(shinystan)
library(gridExtra)
library(caret)
library(cowplot)
library(lubridate)
library(stringr)
library(ggridges)
set.seed(102)
quoteData  = read_csv('C:/Users/ellen/Documents/UH/Fall 2020/Data/CRMData.csv')
quoteData$Office = factor(quoteData$Office)
summary(quoteData)
quoteData$Product_ID = factor(quoteData$Product_ID)
quoteData$Competitor_ID = factor(quoteData$Competitor_ID)
quoteData$Office = factor(quoteData$Office)
quoteData$Date_Due = ymd(quoteData$Date_Due)
quoteData$Date_Submitted = ymd(quoteData$Date_Submitted)
quoteData$Date_Required = ymd(quoteData$Date_Required)
quoteData$ATP = ymd(quoteData$ATP)
quoteData$QuoteDiff = as.numeric(quoteData$Competitor_Quote - quoteData$Quote)
quoteData$ATPDiff = as.numeric(quoteData$Date_Required - quoteData$ATP)
quoteData$RFPDiff = as.numeric(quoteData$Date_Due - quoteData$Date_Submitted)
quoteData$Order = factor(quoteData$Order)
quoteData$Product_ID = factor(quoteData$Product_ID)
# always needs to be releveled after csv
quoteData$RSFDesc = factor(quoteData$RSFDesc,
levels = c("Green", "Silver", "Gold", "Platinum"))
quoteData$RSF = factor(quoteData$RSF,
levels = c(1, 2, 3, 4))
quoteData <- quoteData %>% rownames_to_column("SampleID")
newtrain  = quoteData %>% drop_na()
Missing = quoteData %>% anti_join(newtrain, by = "SampleID")
#quoteData$SampleID  <- as.numeric(quoteData$SampleID)
quoteData$QuoteDiff <- quoteData$QuoteDiff/1000
#train <- sample_n(newtrain, nrow(quoteData)-100)
test <- quoteData %>% anti_join(newtrain, by = "SampleID")
xTrain <- select(newtrain, Product_ID, QuoteDiff)
xTest <-  select(test, Product_ID, QuoteDiff)
x_train <- as.numeric(train$QuoteDiff)
y_train <- as.integer(newtrain$Order)
N_train <- length(newtrain)
# Quick Priors:
glm.priors <- glm(Order ~ Product_ID -1, data = newtrain, family = binomial)
mQuotes = model.matrix(Order ~ Product_ID, data = newtrain)
mTrain = model.matrix(Order ~ Product_ID, data = newtrain)
mTest = model.matrix(Order ~ Product_ID, data = test)
beta = as.numeric(glm.priors$coefficients)
# new adjustments
quoteDiff <- as.numeric(train$QuoteDiff)
N_train <- length(quoteDiff)
quoteData$Product_ID = as.numeric(quoteData$Product_ID)
#test$Product_ID = as.numeric(test$Product_ID)
newtrain  = quoteData %>% drop_na()
Missing = quoteData %>% anti_join(newtrain, by = "SampleID")
xNewTrain <- select(newtrain, Order, Product_ID, QuoteDiff)
mTrain = model.matrix(Order ~ Product_ID + QuoteDiff, data = xNewTrain)[,-1]
mTest = model.matrix(Order ~ Product_ID + QuoteDiff, data = test)[,-1]
#xNewTrain$Order = xNewTrain$Order + 1
# back and forth here:
xNewTrain$Order = as.numeric(xNewTrain$Order) -1
stanMod <- '
data {
int N_train;
int K;
int y_train[N_train];
matrix[N_train, K] x_train;
real p_b[K];
real<lower = 0> p_sb[K];
}
parameters {
vector[K] beta;
}
transformed parameters {
vector[N_train] y_hat;
for(n in 1:N_train)
y_hat[n] = x_train[n]*beta;
}
model {
target += normal_lpdf(beta | p_b, p_sb);
target += bernoulli_lpmf(y_train | inv_logit(y_hat));
}
'
beta = as.numeric(glm.priors$coefficients)
betaSigma  = rep(.2, 6)
fit <- stan(model_code=stanMod,
data = list(
N_train=nrow(mTrain),
K=ncol(mTrain),
y_train=as.numeric(newtrain$Order),
x_train=mTrain,
p_b = beta,
p_sb = betaSigma
))
beta
mTrain
library(lme4)
library(tidyverse)
library(rstan)
library(shinystan)
library(gridExtra)
library(caret)
library(cowplot)
library(lubridate)
library(stringr)
library(ggridges)
set.seed(102)
quoteData  = read_csv('C:/Users/ellen/Documents/UH/Fall 2020/Data/CRMData.csv')
quoteData$Office = factor(quoteData$Office)
summary(quoteData)
quoteData$Product_ID = factor(quoteData$Product_ID)
quoteData$Competitor_ID = factor(quoteData$Competitor_ID)
quoteData$Office = factor(quoteData$Office)
quoteData$Date_Due = ymd(quoteData$Date_Due)
quoteData$Date_Submitted = ymd(quoteData$Date_Submitted)
quoteData$Date_Required = ymd(quoteData$Date_Required)
quoteData$ATP = ymd(quoteData$ATP)
quoteData$QuoteDiff = as.numeric(quoteData$Competitor_Quote - quoteData$Quote)
quoteData$ATPDiff = as.numeric(quoteData$Date_Required - quoteData$ATP)
quoteData$RFPDiff = as.numeric(quoteData$Date_Due - quoteData$Date_Submitted)
quoteData$Order = factor(quoteData$Order)
quoteData$Product_ID = factor(quoteData$Product_ID)
# always needs to be releveled after csv
quoteData$RSFDesc = factor(quoteData$RSFDesc,
levels = c("Green", "Silver", "Gold", "Platinum"))
quoteData$RSF = factor(quoteData$RSF,
levels = c(1, 2, 3, 4))
quoteData <- quoteData %>% rownames_to_column("SampleID")
newtrain  = quoteData %>% drop_na()
Missing = quoteData %>% anti_join(newtrain, by = "SampleID")
newtrain  = quoteData %>% drop_na()
Missing = quoteData %>% anti_join(newtrain, by = "SampleID")
test <- quoteData %>% anti_join(newtrain, by = "SampleID")
xTrain <- select(newtrain, Product_ID, QuoteDiff)
xTest <-  select(test, Product_ID, QuoteDiff)
x_train <- as.numeric(train$QuoteDiff)
#y_train <- as.integer(newtrain$Order)
N_train <- length(newtrain)
x_train <- as.numeric(xTrain$QuoteDiff)
N_train <- length(xTrain)
glm.priors <- glm(Order ~ Product_ID -1, data = newtrain, family = binomial)
mQuotes = model.matrix(Order ~ Product_ID, data = newtrain)
mTrain = model.matrix(Order ~ Product_ID, data = newtrain)
mTest = model.matrix(Order ~ Product_ID, data = test)
beta = as.numeric(glm.priors$coefficients)
beta
stanMod <- '
data {
int N_train;
int K;
int y_train[N_train];
matrix[N_train, K] x_train;
real p_b[K];
real<lower = 0> p_sb[K];
}
parameters {
vector[K] beta;
}
transformed parameters {
vector[N_train] y_hat;
for(n in 1:N_train)
y_hat[n] = x_train[n]*beta;
}
model {
target += normal_lpdf(beta | p_b, p_sb);
target += bernoulli_lpmf(y_train | inv_logit(y_hat));
}
'
beta = as.numeric(glm.priors$coefficients)
beta
betaSigma  = rep(.2, 6)
fit <- stan(model_code=stanMod,
data = list(
N_train=nrow(mTrain),
K=ncol(mTrain),
y_train=as.numeric(newtrain$Order),
x_train=mTrain,
p_b = beta,
p_sb = betaSigma
))
as.numeric(newtrain$Order)-1
fit <- stan(model_code=stanMod,
data = list(
N_train=nrow(mTrain),
K=ncol(mTrain),
y_train=as.numeric(newtrain$Order)-1,
x_train=mTrain,
p_b = beta,
p_sb = betaSigma
))
library(lme4)
library(tidyverse)
library(rstan)
library(shinystan)
library(gridExtra)
library(caret)
library(cowplot)
library(lubridate)
library(stringr)
library(ggridges)
set.seed(102)
quoteData  = read_csv('C:/Users/ellen/Documents/UH/Fall 2020/Data/CRMData.csv')
quoteData$Office = factor(quoteData$Office)
summary(quoteData)
quoteData$Product_ID = factor(quoteData$Product_ID)
quoteData$Competitor_ID = factor(quoteData$Competitor_ID)
quoteData$Office = factor(quoteData$Office)
quoteData$Date_Due = ymd(quoteData$Date_Due)
quoteData$Date_Submitted = ymd(quoteData$Date_Submitted)
quoteData$Date_Required = ymd(quoteData$Date_Required)
quoteData$ATP = ymd(quoteData$ATP)
quoteData$QuoteDiff = as.numeric(quoteData$Competitor_Quote - quoteData$Quote)
quoteData$ATPDiff = as.numeric(quoteData$Date_Required - quoteData$ATP)
quoteData$RFPDiff = as.numeric(quoteData$Date_Due - quoteData$Date_Submitted)
quoteData$Order = factor(quoteData$Order)
quoteData$Product_ID = factor(quoteData$Product_ID)
# always needs to be releveled after csv
quoteData$RSFDesc = factor(quoteData$RSFDesc,
levels = c("Green", "Silver", "Gold", "Platinum"))
quoteData$RSF = factor(quoteData$RSF,
levels = c(1, 2, 3, 4))
quoteData <- quoteData %>% rownames_to_column("SampleID")
#quoteData$SampleID  <- as.numeric(quoteData$SampleID)
quoteData$QuoteDiff <- quoteData$QuoteDiff/1000
#train <- sample_n(newtrain, nrow(quoteData)-100)
newtrain  = quoteData %>% drop_na()
Missing = quoteData %>% anti_join(newtrain, by = "SampleID")
test <- quoteData %>% anti_join(newtrain, by = "SampleID")
xTrain <- select(newtrain, Product_ID, QuoteDiff)
xTest <-  select(test, Product_ID, QuoteDiff)
x_train <- as.numeric(xTrain$QuoteDiff)
#y_train <- as.integer(newtrain$Order)
N_train <- length(xTrain)
# Quick Priors:
glm.priors <- glm(Order ~ Product_ID -1, data = newtrain, family = binomial)
mQuotes = model.matrix(Order ~ Product_ID, data = newtrain)
mTrain = model.matrix(Order ~ Product_ID, data = newtrain)
mTest = model.matrix(Order ~ Product_ID, data = test)
beta = as.numeric(glm.priors$coefficients)
# ---------- #
stanMod <- '
data {
int N_train;
int K;
int y_train[N_train];
matrix[N_train, K] x_train;
real p_b[K];
real<lower = 0> p_sb[K];
}
parameters {
vector[K] beta;
}
transformed parameters {
vector[N_train] y_hat;
for(n in 1:N_train)
y_hat[n] = x_train[n]*beta;
}
model {
target += normal_lpdf(beta | p_b, p_sb);
target += bernoulli_lpmf(y_train | inv_logit(y_hat));
}
'
beta = as.numeric(glm.priors$coefficients)
betaSigma  = rep(.2, 6)
fit <- stan(model_code=stanMod,
data = list(
N_train=nrow(mTrain),
K=ncol(mTrain),
y_train=as.numeric(newtrain$Order)-1,
x_train=mTrain,
p_b = beta,
p_sb = betaSigma
))
Coef <- summary(fit, pars = c('beta'), probs = c(0.1, 0.9))$summary[,1]
Stanbeta = summary(fit, pars = c('beta'), probs = c(0.1, 0.9))$summary[,1]
test$Prob <- exp(t(Stanbeta%*%t(mTest)))/(1+exp(t(Stanbeta%*%t(mTest))))
test = test %>% mutate (Class = if_else(Prob < .5, 0, 1))
confusionMatrix(factor(test$Class), factor(test$Result), positive = "1")
confusionMatrix(factor(test$Class), factor(test$Order), positive = "1")
glm.priors
glm.priors <- glm(Order ~ Product_ID -1, data = newtrain, family = binomial)
test$Prob <- predict(glm.priors, type = "response", newdata = test)
test = test %>% mutate (Class = if_else(Prob < .5, 0, 1))
confusionMatrix(factor(test$Class), factor(test$Order), positive = "1")
View(test)
library(lme4)
library(tidyverse)
library(rstan)
library(shinystan)
library(gridExtra)
library(caret)
library(cowplot)
library(lubridate)
library(stringr)
library(ggridges)
set.seed(102)
quoteData  = read_csv('C:/Users/ellen/Documents/UH/Fall 2020/Data/CRMData.csv')
quoteData$Office = factor(quoteData$Office)
summary(quoteData)
quoteData$Product_ID = factor(quoteData$Product_ID)
quoteData$Competitor_ID = factor(quoteData$Competitor_ID)
quoteData$Office = factor(quoteData$Office)
quoteData$Date_Due = ymd(quoteData$Date_Due)
quoteData$Date_Submitted = ymd(quoteData$Date_Submitted)
quoteData$Date_Required = ymd(quoteData$Date_Required)
quoteData$ATP = ymd(quoteData$ATP)
quoteData$QuoteDiff = as.numeric(quoteData$Competitor_Quote - quoteData$Quote)
quoteData$ATPDiff = as.numeric(quoteData$Date_Required - quoteData$ATP)
quoteData$RFPDiff = as.numeric(quoteData$Date_Due - quoteData$Date_Submitted)
quoteData$Order = factor(quoteData$Order)
quoteData$Product_ID = factor(quoteData$Product_ID)
# always needs to be releveled after csv
quoteData$RSFDesc = factor(quoteData$RSFDesc,
levels = c("Green", "Silver", "Gold", "Platinum"))
quoteData$RSF = factor(quoteData$RSF,
levels = c(1, 2, 3, 4))
quoteData <- quoteData %>% rownames_to_column("SampleID")
#quoteData$SampleID  <- as.numeric(quoteData$SampleID)
quoteData$QuoteDiff <- quoteData$QuoteDiff/1000
newtrain  = quoteData %>% drop_na()
Missing = quoteData %>% anti_join(newtrain, by = "SampleID")
test <- quoteData %>% anti_join(newtrain, by = "SampleID")
View(test)
xTrain <- select(newtrain, Product_ID, QuoteDiff)
xTest <-  select(test, Product_ID, QuoteDiff)
x_train <- as.numeric(xTrain$QuoteDiff)
#y_train <- as.integer(newtrain$Order)
N_train <- length(xTrain)
glm.priors <- glm(Order ~ Product_ID -1, data = newtrain, family = binomial)
test$Prob <- predict(glm.priors, type = "response", newdata = test)
test = test %>% mutate (Class = if_else(Prob < .5, 0, 1))
confusionMatrix(factor(test$Class), factor(test$Order), positive = "1")
newtrain
glm.priors <- glm(Order ~ Product_ID + QuoteDiff -1, data = newtrain, family = binomial)
test$Prob <- predict(glm.priors, type = "response", newdata = test)
test = test %>% mutate (Class = if_else(Prob < .5, 0, 1))
confusionMatrix(factor(test$Class), factor(test$Order), positive = "1")
mQuotes = model.matrix(Order ~ Product_ID + QuoteDiff, data = newtrain)
mTrain = model.matrix(Order ~ Product_ID + QuoteDiff, data = newtrain)
mTest = model.matrix(Order ~ Product_ID + QuoteDiff, data = test)
View(mTrain)
mQuotes = model.matrix(Order ~ Product_ID + QuoteDiff, data = newtrain)[,-1]
mTrain = model.matrix(Order ~ Product_ID + QuoteDiff, data = newtrain)[,-1]
mTest = model.matrix(Order ~ Product_ID + QuoteDiff, data = test)[,-1]
View(mQuotes)
beta = as.numeric(glm.priors$coefficients)
# ---------- #
stanMod <- '
data {
int N_train;
int K;
int y_train[N_train];
matrix[N_train, K] x_train;
real p_b[K];
real<lower = 0> p_sb[K];
}
parameters {
vector[K] beta;
}
transformed parameters {
vector[N_train] y_hat;
for(n in 1:N_train)
y_hat[n] = x_train[n]*beta;
}
model {
target += normal_lpdf(beta | p_b, p_sb);
target += bernoulli_lpmf(y_train | inv_logit(y_hat));
}
'
beta = as.numeric(glm.priors$coefficients)
beta
betaSigma  = rep(.2, 7)
fit <- stan(model_code=stanMod,
data = list(
N_train=nrow(mTrain),
K=ncol(mTrain),
y_train=as.numeric(newtrain$Order)-1,
x_train=mTrain,
p_b = beta,
p_sb = betaSigma
))
ncol(mTrain)
beta
as.numeric(newtrain$Order)-1
fit <- stan(model_code=stanMod,
data = list(
N_train=nrow(mTrain),
K=ncol(mTrain),
y_train=as.numeric(newtrain$Order)-1,
x_train=mTrain,
p_b = beta,
p_sb = betaSigma
))
ncol(mTrain)
mTrain
betaSigma  = rep(.2, 6)
fit <- stan(model_code=stanMod,
data = list(
N_train=nrow(mTrain),
K=ncol(mTrain),
y_train=as.numeric(newtrain$Order)-1,
x_train=mTrain,
p_b = beta,
p_sb = betaSigma
))
beta
fit <- stan(model_code=stanMod,
data = list(
N_train=nrow(mTrain),
K=ncol(mTrain),
y_train=as.numeric(newtrain$Order)-1,
x_train=mTrain,
p_b = rep(1,6),
p_sb = betaSigma
))
Coef <- summary(fit, pars = c('beta'), probs = c(0.1, 0.9))$summary[,1]
Coef
Stanbeta = summary(fit, pars = c('beta'), probs = c(0.1, 0.9))$summary[,1]
test$Prob <- exp(t(Stanbeta%*%t(mTest)))/(1+exp(t(Stanbeta%*%t(mTest))))
test = test %>% mutate (Class = if_else(Prob < .5, 0, 1))
confusionMatrix(factor(test$Class), factor(test$Order), positive = "1")
fit
y_hat = summary(fit, pars = c('y_hat'), probs = c(0.1, 0.9))$summary[,1]
y_hat
